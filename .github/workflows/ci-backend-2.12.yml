name: Build 2.12

on:
  push:
    branches:
      - master
  pull_request:

jobs:
  build:

    runs-on: ubuntu-latest
    
    steps:
    - uses: actions/checkout@v1
    - uses: actions/setup-python@v1
      with:
        python-version: '3.7'
        architecture: 'x64'
    - uses: actions/setup-java@v1
      with:
        java-version: 8
        architecture: x64
    - name: Build
      run: |
        echo "Setting up Python dependencies"
        pip install -r ./requirements.txt
        jep_site_packages_path=`pip show jep | grep "^Location:" | cut -d ':' -f 2 | cut -d ' ' -f 2`
        jep_path=${jep_site_packages_path}/jep
        jep_lib_path=`realpath ${jep_site_packages_path}/../../`
        export LD_LIBRARY_PATH=${jep_path}:${jep_site_packages_path}:${jep_lib_path}:${LD_LIBRARY_PATH}
        export LD_PRELOAD=${jep_lib_path}/libpython3.so

        echo "Downloading Spark 2.4.4"
        wget -q https://archive.apache.org/dist/spark/spark-2.4.4/spark-2.4.4-bin-hadoop2.7.tgz
        tar xfz spark-2.4.4-bin-hadoop2.7.tgz
        rm spark-2.4.4-bin-hadoop2.7.tgz
        wget -q https://archive.apache.org/dist/spark/spark-2.4.4/spark-2.4.4-bin-without-hadoop-scala-2.12.tgz
        tar xfz spark-2.4.4-bin-without-hadoop-scala-2.12.tgz
        rm spark-2.4.4-bin-without-hadoop-scala-2.12.tgz
        for jar in `ls spark-2.4.4-bin-hadoop2.7/jars |grep -v '2\.11'`; do cp spark-2.4.4-bin-hadoop2.7/jars/$jar spark-2.4.4-bin-without-hadoop-scala-2.12/jars; done

        export SPARK_HOME=`pwd`"/spark-2.4.4-bin-without-hadoop-scala-2.12"
        export PATH="$SPARK_HOME/bin:$PATH"

        echo "Testing with Scala 2.12"
        pushd $GITHUB_WORKSPACE
          sbt ++2.12.10 test
        popd